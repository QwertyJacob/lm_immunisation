{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Challenge: Running AntiDote's Arms Race in Miniature\n",
    "\n",
    "**Welcome to the final challenge!**  \n",
    "In this 25-minute activity, you'll simulate AntiDote's bi-level adversarial training on a tiny scale.  \n",
    "Watch the defender LLM and adversary hypernetwork co-evolve in an arms race — right in your Colab.  \n",
    "\n",
    "**Your task:**  \n",
    "1. Load the model + datasets (micro subsets of BeaverTails and LIMA).  \n",
    "2. Attach defender LoRA (rank=4).  \n",
    "3. Instantiate tiny adversary hypernetwork.  \n",
    "4. Run the training loop: 3 blocks of (5 adversary steps + 5 defender steps).  \n",
    "5. Plot the losses: adversary harm (should drop then rise), defender harm + capability.  \n",
    "\n",
    "**Challenge question:**  \n",
    "Modify *one* hyperparameter (assigned to your group: adversary_lr, lora_rank, or adv_def_ratio).  \n",
    "Run again. Did the arms race stabilize (defender holds), adversary dominate (harm keeps dropping), or defender win early?  \n",
    "Class discussion: which param matters most for early robustness? (Connects to paper's decoupled loss ablation.)  \n",
    "(Report in final cell. Best analysis wins a prize!)  \n",
    "\n",
    "**Time breakdown:**  \n",
    "- 5' setup/reading  \n",
    "- 15' run/modify/experiment (ask for hints!)  \n",
    "- 5' report + prize  \n",
    "\n",
    "**Hints:**  \n",
    "- Use batch_size=2 for speed.  \n",
    "- If OOM, reduce rank to 2.  \n",
    "- Expect ~5-10 min runtime on T4.  \n",
    "\n",
    "Runtime: Colab T4 GPU (free tier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers datasets peft torch matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Qwen2-0.5B-Instruct (small, aligned)\n",
    "MODEL_ID = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=DEVICE,\n",
    ")\n",
    "base_model.eval()\n",
    "\n",
    "HIDDEN_DIM = base_model.config.hidden_size\n",
    "N_LAYERS = base_model.config.num_hidden_layers\n",
    "print(f\"Layers: {N_LAYERS}, Hidden dim: {HIDDEN_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Micro-Datasets\n",
    "\n",
    "- Harmful: 8 from BeaverTails (prompt + harmful/safe pairs for DPO).\n",
    "- Benign: 8 from LIMA (capability preservation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load micro subsets\n",
    "beaver = load_dataset(\"PKU-Alignment/BeaverTails\", split=\"train\").shuffle(seed=42).select(range(8))\n",
    "lima = load_dataset(\"GAIR/lima\", split=\"train\").shuffle(seed=42).select(range(8))\n",
    "\n",
    "# Format for DPO: (prompt, safe, harmful)\n",
    "safe_data = [(ex['prompt'], ex['response_safe']) for ex in beaver]\n",
    "harm_data = [(ex['prompt'], ex['response_unsafe']) for ex in beaver]\n",
    "\n",
    "# Benign for capability: (prompt, response)\n",
    "cap_data = [(ex['conversations'][0], ex['conversations'][1]) for ex in lima]\n",
    "\n",
    "print(f\"Harmful pairs: {len(harm_data)}, Benign: {len(cap_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "def tokenize_pairs(pairs, is_dpo=False):\n",
    "    texts = [f\"User: {p}\\nAssistant: {r}{tokenizer.eos_token}\" for p, r in pairs]\n",
    "    enc = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LEN).to(DEVICE)\n",
    "    labels = enc[\"input_ids\"].clone()\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    enc[\"labels\"] = labels\n",
    "    return enc\n",
    "\n",
    "safe_enc = tokenize_pairs(safe_data)\n",
    "harm_enc = tokenize_pairs(harm_data)\n",
    "cap_enc = tokenize_pairs(cap_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adversary Hypernetwork\n",
    "\n",
    "Tiny version: input activations → self-attn → FF → U/V heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyHypernetwork(nn.Module):\n",
    "    def __init__(self, input_dim=HIDDEN_DIM, rank=4, hidden_dim=128, n_heads=2):\n",
    "        super().__init__()\n",
    "        self.rank = rank\n",
    "        self.attn = nn.MultiheadAttention(input_dim, n_heads)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "        self.head_u = nn.Linear(input_dim, rank * input_dim)\n",
    "        self.head_v = nn.Linear(input_dim, input_dim * rank)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, D)\n",
    "        x = x.transpose(0, 1)  # (T, B, D)\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        attn_out = attn_out.transpose(0, 1)  # (B, T, D)\n",
    "        pooled = attn_out.mean(dim=1)  # (B, D)\n",
    "        emb = self.ff(pooled)\n",
    "        u = self.head_u(emb).view(-1, self.rank, HIDDEN_DIM)\n",
    "        v = self.head_v(emb).view(-1, HIDDEN_DIM, self.rank)\n",
    "        return u, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Activation Hooks + Patch Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, inputs, layer_idx):\n",
    "    activations = {}\n",
    "    def hook(module, inp, out):\n",
    "        activations['act'] = out[0].detach()\n",
    "    handle = model.model.layers[layer_idx].register_forward_hook(hook)\n",
    "    model(**inputs)\n",
    "    handle.remove()\n",
    "    return activations['act']\n",
    "\n",
    "class AttackedModel:\n",
    "    def __init__(self, base_model, layer_idx):\n",
    "        self.model = deepcopy(base_model)\n",
    "        self.layer_idx = layer_idx\n",
    "\n",
    "    def apply_patch(self, u, v):\n",
    "        delta_w = v.transpose(1, 2) @ u  # (B, D_out, D_in)\n",
    "        # Assume injecting into mlp.fc1 for simplicity\n",
    "        target = self.model.model.layers[self.layer_idx].mlp.gate_proj\n",
    "        target.weight.data += delta_w.squeeze(0)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        return self.model(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Losses\n",
    "\n",
    "- Harm: Negative DPO (adversary max, defender min).\n",
    "- Cap: CE + KL to base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpo_loss(pi_safe, pi_harm):\n",
    "    # Simplified: log sigmoid (pi_safe - pi_harm)\n",
    "    return -F.logsigmoid(pi_safe - pi_harm).mean()\n",
    "\n",
    "def harm_loss(model, safe_enc, harm_enc):\n",
    "    # Compute logprobs on safe/harm\n",
    "    safe_out = model(**safe_enc).logits\n",
    "    harm_out = model(**harm_enc).logits\n",
    "    # Shift for next-token\n",
    "    pi_safe = F.log_softmax(safe_out[:, :-1], dim=-1).gather(-1, safe_enc['labels'][:, 1:].unsqueeze(-1)).mean()\n",
    "    pi_harm = F.log_softmax(harm_out[:, :-1], dim=-1).gather(-1, harm_enc['labels'][:, 1:].unsqueeze(-1)).mean()\n",
    "    return -dpo_loss(pi_safe, pi_harm)  # Negative for adversary max\n",
    "\n",
    "def cap_loss(model, cap_enc, base_model):\n",
    "    out = model(**cap_enc)\n",
    "    ce = out.loss\n",
    "    base_logits = base_model(**cap_enc).logits\n",
    "    kl = F.kl_div(F.log_softmax(out.logits, dim=-1), F.softmax(base_logits, dim=-1), reduction='batchmean')\n",
    "    return ce + 0.1 * kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop\n",
    "\n",
    "Alternate phases A (adv/def on attacked) and B (def on clean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams — MODIFY ONE FOR CHALLENGE!\n",
    "adv_lr = 1e-4  # Group 1: try 5e-4 or 1e-5\n",
    "def_lr = 3e-5\n",
    "lora_rank = 4  # Group 2: try 2 or 8\n",
    "adv_steps_per_block = 5  # Group 3: try 2:8 or 8:2 ratio\n",
    "def_steps_per_block = 5\n",
    "n_blocks = 3\n",
    "target_layer = 10  # Fixed for micro\n",
    "\n",
    "# Defender LoRA\n",
    "lora_config = LoraConfig(r=lora_rank, lora_alpha=16, target_modules=[\"q_proj\", \"v_proj\"])\n",
    "defender = get_peft_model(deepcopy(base_model), lora_config).to(DEVICE)\n",
    "def_opt = torch.optim.Adam(defender.parameters(), lr=def_lr)\n",
    "\n",
    "# Adversary\n",
    "adversary = TinyHypernetwork(rank=lora_rank).to(DEVICE)\n",
    "adv_opt = torch.optim.Adam(adversary.parameters(), lr=adv_lr)\n",
    "\n",
    "adv_losses = []\n",
    "def_harm_losses = []\n",
    "cap_losses = []\n",
    "\n",
    "for block in range(n_blocks):\n",
    "    print(f\"Block {block+1}/{n_blocks}\")\n",
    "    \n",
    "    # Phase A: Adversary max harm\n",
    "    for _ in range(adv_steps_per_block):\n",
    "        acts = get_activations(defender, safe_enc, target_layer)  # Or harm_enc\n",
    "        u, v = adversary(acts)\n",
    "        attacked = AttackedModel(defender, target_layer)\n",
    "        attacked.apply_patch(u, v)\n",
    "        loss_a = harm_loss(attacked.model, safe_enc, harm_enc)\n",
    "        adv_opt.zero_grad()\n",
    "        loss_a.backward()\n",
    "        adv_opt.step()\n",
    "        adv_losses.append(loss_a.item())\n",
    "    \n",
    "    # Phase A: Defender min harm under attack\n",
    "    for _ in range(def_steps_per_block):\n",
    "        acts = get_activations(defender, safe_enc, target_layer)\n",
    "        u, v = adversary(acts)\n",
    "        attacked = AttackedModel(defender, target_layer)\n",
    "        attacked.apply_patch(u, v)\n",
    "        loss_d = harm_loss(attacked.model, safe_enc, harm_enc)\n",
    "        def_opt.zero_grad()\n",
    "        loss_d.backward()\n",
    "        def_opt.step()\n",
    "        def_harm_losses.append(loss_d.item())\n",
    "    \n",
    "    # Phase B: Defender min cap on clean\n",
    "    for _ in range(def_steps_per_block):\n",
    "        loss_c = cap_loss(defender, cap_enc, base_model)\n",
    "        def_opt.zero_grad()\n",
    "        loss_c.backward()\n",
    "        def_opt.step()\n",
    "        cap_losses.append(loss_c.item())\n",
    "\n",
    "# Extend lists to same length for plotting\n",
    "max_len = max(len(adv_losses), len(def_harm_losses), len(cap_losses))\n",
    "adv_losses += [np.nan] * (max_len - len(adv_losses))\n",
    "def_harm_losses += [np.nan] * (max_len - len(def_harm_losses))\n",
    "cap_losses += [np.nan] * (max_len - len(cap_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = range(max_len)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, adv_losses, 'r-', label='Adversary Harm Loss (max)')\n",
    "plt.plot(steps, def_harm_losses, 'b-', label='Defender Harm Loss (min)')\n",
    "plt.plot(steps, cap_losses, 'g-', label='Capability Loss (min)')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('AntiDote Arms Race: Losses Over Time')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Challenge Report\n",
    "\n",
    "Modified param: ________  \n",
    "New value: ________  \n",
    "\n",
    "Outcome: (stabilize / adv dominate / def early win)  \n",
    "\n",
    "Insight: (1-2 sentences on why this param affects early robustness, link to paper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
